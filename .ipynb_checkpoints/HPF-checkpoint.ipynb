{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os.path\n",
    "import random\n",
    "\n",
    "from edward.models import Poisson,Gamma\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movielens(binary,threshold):\n",
    "    file_path = 'data/movielens/X.txt'\n",
    "    train_mask_file = 'data/movielens/train_mask.txt'\n",
    "    test_mask_file = 'data/movielens/test_mask.txt'\n",
    "    X = np.loadtxt(file_path)\n",
    "    x_train = np.array(X)\n",
    "    train_mask = np.loadtxt(train_mask_file)\n",
    "    test_mask = np.loadtxt(test_mask_file)\n",
    "    \n",
    "    for i in range(0,X.shape[0]):\n",
    "        for j in range(0,X.shape[1]):\n",
    "            if train_mask[i][j] == 0:\n",
    "                x_train[i][j] = 0\n",
    "\n",
    "    \n",
    "    if binary == False:\n",
    "        return x_train,X,test_mask\n",
    "    \n",
    "    for i in range(0,X.shape[0]):\n",
    "        for j in range(0,X.shape[1]):\n",
    "            if x_train[i][j] <= threshold:\n",
    "                x_train[i][j] = 0\n",
    "            else:\n",
    "                x_train[i][j] = 1\n",
    "                \n",
    "    return x_train,X,test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,X_full,test_mask = movielens(True,0)\n",
    "k = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "initialize() got an unexpected keyword argument 'k1_scaling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-ce9b2ed01bb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0minference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0med\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKLqp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0meu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mq_eu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mni\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mq_ni\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mq_theta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mq_beta\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0minference\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mk1_scaling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0meu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mni\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jarvis/src/edward/edward/inferences/klqp.pyc\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, n_samples, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \"\"\"\n\u001b[1;32m     65\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKLqp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbuild_loss_and_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jarvis/src/edward/edward/inferences/variational_inference.pyc\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self, optimizer, var_list, use_prettytensor, *args, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m       \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m \u001b[0mTensorFlow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \"\"\"\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariationalInference\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvar_list\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: initialize() got an unexpected keyword argument 'k1_scaling'"
     ]
    }
   ],
   "source": [
    "users = X_full.shape[0]\n",
    "movies = X_full.shape[1]\n",
    "a = a_c = c = c_c = 0.3\n",
    "b_c = d_c = 1.0\n",
    "scale = 0.001\n",
    "\n",
    "eu = Gamma(a_c*tf.ones([users,k]),(a_c/b_c)*tf.ones([users,k]))\n",
    "ni = Gamma(c_c*tf.ones([movies,k]),(c_c/d_c)*tf.ones([movies,k]))\n",
    "theta = Gamma(a*tf.ones([users,k]),eu)\n",
    "beta = Gamma(c*tf.ones([movies,k]),ni)\n",
    "lam1 = tf.matmul(theta,beta,transpose_b=True)\n",
    "x = Poisson(lam = lam1,value = tf.ones([users,movies]))\n",
    "\n",
    "q_eu = Gamma(tf.nn.softplus(tf.Variable(a_c*tf.ones([users,k]))),tf.nn.softplus(tf.Variable((a_c/b_c)*tf.ones([users,k]))))\n",
    "q_ni = Gamma(tf.nn.softplus(tf.Variable(c_c*tf.ones([movies,k]))),tf.nn.softplus(tf.Variable((c_c/d_c)*tf.ones([movies,k]))))\n",
    "q_theta = Gamma(tf.nn.softplus(tf.Variable(a*tf.ones([users,k]))),tf.nn.softplus(tf.Variable(eu)))\n",
    "q_beta = Gamma(tf.nn.softplus(tf.Variable(c*tf.ones([movies,k]))),tf.nn.softplus(tf.Variable(ni)))\n",
    "\n",
    "\n",
    "#q_eu = Gamma(tf.Variable(a_c*tf.ones([users,k])),tf.Variable((a_c/b_c)*tf.ones([users,k])))\n",
    "#q_ni = Gamma(tf.Variable(c_c*tf.ones([movies,k])),tf.Variable((c_c/d_c)*tf.ones([movies,k])))\n",
    "#q_theta = Gamma(tf.Variable(a*tf.ones([users,k])),tf.Variable(eu))\n",
    "#q_beta = Gamma(tf.Variable(c*tf.ones([movies,k])),tf.Variable(ni))\n",
    "\n",
    "inference = ed.KLqp({eu:q_eu,ni:q_ni,theta: q_theta,beta: q_beta},data={x:x_train})\n",
    "inference.initialize(n_samples=1,scale={eu:scale,ni:scale,theta:scale,beta:scale})\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "init.run()\n",
    "inference.run(n_iter = 100,n_print=5)\n",
    "#for i in range (1,inference.n_iter):\n",
    "    #inference.update()\n",
    "    #if i%10 == 0:\n",
    "     #   print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ nan  nan  nan ...,  nan  nan  nan]\n",
      "  [ nan  nan  nan ...,  nan  nan  nan]\n",
      "  [ nan  nan  nan ...,  nan  nan  nan]\n",
      "  ..., \n",
      "  [ nan  nan  nan ...,  nan  nan  nan]\n",
      "  [ nan  nan  nan ...,  nan  nan  nan]\n",
      "  [ nan  nan  nan ...,  nan  nan  nan]]]\n"
     ]
    }
   ],
   "source": [
    "print(q_theta.sample(1).eval())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:bml]",
   "language": "python",
   "name": "conda-env-bml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
