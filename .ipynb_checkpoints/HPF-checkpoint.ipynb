{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import edward as ed\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os.path\n",
    "import random\n",
    "import scipy.special as sp\n",
    "\n",
    "from edward.models import Poisson,Gamma\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def movielens(binary,threshold):\n",
    "    file_path = 'data/movielens/X.txt'\n",
    "    train_mask_file = 'data/movielens/train_mask.txt'\n",
    "    test_mask_file = 'data/movielens/test_mask.txt'\n",
    "    X = np.loadtxt(file_path)\n",
    "    x_train = np.array(X)\n",
    "    train_mask = np.loadtxt(train_mask_file)\n",
    "    test_mask = np.loadtxt(test_mask_file)\n",
    "    \n",
    "    for i in range(0,X.shape[0]):\n",
    "        for j in range(0,X.shape[1]):\n",
    "            if train_mask[i][j] == 0:\n",
    "                x_train[i][j] = 0\n",
    "\n",
    "    \n",
    "    if binary == False:\n",
    "        return x_train,X,test_mask\n",
    "    \n",
    "    for i in range(0,X.shape[0]):\n",
    "        for j in range(0,X.shape[1]):\n",
    "            if x_train[i][j] <= threshold:\n",
    "                x_train[i][j] = 0\n",
    "            else:\n",
    "                x_train[i][j] = 1\n",
    "                \n",
    "    for i in range(0,X.shape[0]):\n",
    "        for j in range(0,X.shape[1]):\n",
    "            if X[i][j] <= threshold:\n",
    "                X[i][j] = 0\n",
    "            else:\n",
    "                X[i][j] = 1\n",
    "    \n",
    "    return x_train,X,test_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,X_full,test_mask = movielens(True,0)\n",
    "y = x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "K = 5\n",
    "users = X_full.shape[0]\n",
    "items = X_full.shape[1]\n",
    "a = a_c = c = c_c = 0.3\n",
    "b_c = d_c = 1.0      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kappa_shp =  np.random.uniform(low=0.1,size=users)\n",
    "kappa_rte = np.random.uniform(low=0.1,size=users)\n",
    "tau_shp = np.random.uniform(low=0.1,size=items)\n",
    "tau_rte = np.random.uniform(low=0.1,size=items)\n",
    "phi = np.zeros([users,items,K])\n",
    "gam_shp = np.random.uniform(low=0.1,size=[users,K])\n",
    "gam_rte = np.random.uniform(low=0.1,size=[users,K])\n",
    "lam_shp = np.random.uniform(low=0.1,size=[items,K])\n",
    "lam_rte = np.random.uniform(low=0.1,size=[items,K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-10-2e033c541854>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-2e033c541854>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    for u range(0,users):\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for u in range(0,users):\n",
    "    kappa_shp[u] = a_c + K*a\n",
    "for i in range(0,items):\n",
    "    tau_shp[i] = c_c + K*c\n",
    "for asd in range(0,100):\n",
    "    print(asd)\n",
    "    \n",
    "    for u in range(0,users):\n",
    "        for i in range(0,items):\n",
    "            if y[u,i] > 0:\n",
    "                phi[u,i,:]= np.exp(sp.digamma(gam_shp[u,:])-np.log(gam_rte[u,:])+sp.digamma(lam_shp[i,:])-np.log(lam_rte[i,:]))\n",
    "            norm = np.sum(phi[u,i,:])\n",
    "            phi[u,i,:] = phi[u,i,:]/norm\n",
    "    \n",
    "    for u in range(0,users):\n",
    "        for k in range(0,K):\n",
    "            gam_shp[u,k] = a + np.inner(y[u,:],phi[u,:,k])\n",
    "            gam_rte[u,k] = (kappa_shp[u]/kappa_rte[u]) + np.sum(lam_shp[:,k]/lam_rte[:,k])\n",
    "        kappa_rte[u] = (a_c/b_c) + np.sum(gam_shp[u,:]/gam_rte[u,:])\n",
    "    \n",
    "    for i in range(0,items):\n",
    "        for k in range(0,K):\n",
    "            lam_shp[i,k] = c + np.inner(y[:,i],phi[:,i,k])\n",
    "            lam_rte[i,k] = (tau_shp[i]/tau_rte[i]) + np.sum(gam_shp[:,k]/gam_rte[:,k])\n",
    "        tau_rte[i] = (c_c/d_c) + np.sum(lam_shp[i,:]/lam_rte[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_theta = Gamma(gam_shp,gam_rte)\n",
    "q_beta = Gamma(lam_shp,lam_rte)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "eu = Gamma(a_c*tf.ones([users,k]),(a_c/b_c)*tf.ones([users,k]))\n",
    "ni = Gamma(c_c*tf.ones([movies,k]),(c_c/d_c)*tf.ones([movies,k]))\n",
    "theta = Gamma(a*tf.ones([users,k]),eu)\n",
    "beta = Gamma(c*tf.ones([movies,k]),ni)\n",
    "lam1 = tf.matmul(theta,beta,transpose_b=True)\n",
    "x = Poisson(lam = lam1,value = tf.ones([users,movies]))\n",
    "\n",
    "q_eu = Gamma(tf.Variable(a_c*tf.ones([users,k])),tf.Variable((a_c/b_c)*tf.ones([users,k])))\n",
    "q_ni = Gamma(tf.Variable(c_c*tf.ones([movies,k])),tf.Variable((c_c/d_c)*tf.ones([movies,k])))\n",
    "q_theta = Gamma(tf.Variable(a*tf.ones([users,k])),tf.Variable(eu))\n",
    "q_beta = Gamma(tf.Variable(c*tf.ones([movies,k])),tf.Variable(ni))\n",
    "\n",
    "\n",
    "inference = ed.ReparameterizationKLKLqp({eu:q_eu,ni:q_ni,theta: q_theta,beta: q_beta},data={x:x_train})\n",
    "inference.initialize(n_samples=1,n_iter=2000,n_print=10)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "init.run()\n",
    "#inference.run(n_iter = 300,n_print=1)\n",
    "for i in range (1,inference.n_iter):\n",
    "    d = inference.update()\n",
    "    inference.print_progress(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_sample = 10\n",
    "beta_sample = q_beta.sample(no_sample).eval()\n",
    "theta_sample = q_theta.sample(no_sample).eval()\n",
    "result = np.zeros([users,movies])\n",
    "for i in range(0,no_sample):\n",
    "    result = np.add(result,np.matmul(theta_sample[i],np.transpose(beta_sample[i])))\n",
    "result /= no_sample\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = 0.0\n",
    "count = 0.0\n",
    "for i in range(0,users):\n",
    "    for j in range(0,movies):\n",
    "        if test_mask[i][j] == 1:\n",
    "            error += pow(X_full[i][j]-result[i][j],2)\n",
    "            count += 1\n",
    "error /= count\n",
    "error = math.sqrt(error)\n",
    "print(error)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:bml]",
   "language": "python",
   "name": "conda-env-bml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
